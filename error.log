[2024-01-02 17:25:44 +0000] [5547] [INFO] Starting gunicorn 21.2.0
[2024-01-02 17:25:44 +0000] [5547] [INFO] Listening at: http://0.0.0.0:8000 (5547)
[2024-01-02 17:25:44 +0000] [5547] [INFO] Using worker: sync
[2024-01-02 17:25:44 +0000] [5548] [INFO] Booting worker with pid: 5548
[2024-01-02 17:25:48 +0000] [5547] [INFO] Handling signal: int
[2024-01-02 17:25:49 +0000] [5548] [INFO] Worker exiting (pid: 5548)
[2024-01-02 17:25:49 +0000] [5547] [INFO] Shutting down: Master
[2024-01-02 17:27:33 +0000] [5779] [INFO] Starting gunicorn 21.2.0
[2024-01-02 17:27:33 +0000] [5779] [INFO] Listening at: http://0.0.0.0:8000 (5779)
[2024-01-02 17:27:33 +0000] [5779] [INFO] Using worker: sync
[2024-01-02 17:27:33 +0000] [5780] [INFO] Booting worker with pid: 5780
[2024-01-02 17:28:18 +0000] [5779] [INFO] Handling signal: int
[2024-01-02 17:28:18 +0000] [5780] [INFO] Worker exiting (pid: 5780)
[2024-01-02 17:28:19 +0000] [5779] [INFO] Shutting down: Master
[2024-01-02 17:30:23 +0000] [6121] [INFO] Starting gunicorn 21.2.0
[2024-01-02 17:30:23 +0000] [6121] [INFO] Listening at: http://0.0.0.0:8000 (6121)
[2024-01-02 17:30:23 +0000] [6121] [INFO] Using worker: sync
[2024-01-02 17:30:23 +0000] [6122] [INFO] Booting worker with pid: 6122
[2024-01-02 17:31:02 +0000] [6121] [INFO] Handling signal: int
[2024-01-02 17:31:02 +0000] [6122] [INFO] Worker exiting (pid: 6122)
[2024-01-02 17:31:03 +0000] [6121] [INFO] Shutting down: Master
[2024-01-02 19:50:26 +0000] [10227] [INFO] Starting gunicorn 21.2.0
[2024-01-02 19:50:26 +0000] [10227] [INFO] Listening at: http://0.0.0.0:8000 (10227)
[2024-01-02 19:50:26 +0000] [10227] [INFO] Using worker: sync
[2024-01-02 19:50:26 +0000] [10228] [INFO] Booting worker with pid: 10228
[2024-01-02 19:52:10,212] [INFO] building CogAgentModel model ...
[2024-01-02 19:52:10,215] [INFO] [RANK 0] > initializing model parallel with size 1
[2024-01-02 19:52:10,215] [INFO] [RANK 0] You didn't pass in LOCAL_WORLD_SIZE environment variable. We use the guessed LOCAL_WORLD_SIZE=1. If this is wrong, please pass the LOCAL_WORLD_SIZE manually.
[2024-01-02 19:52:10,216] [INFO] [RANK 0] You are using model-only mode.
For torch.distributed users or loading model parallel models, set environment variables RANK, WORLD_SIZE and LOCAL_RANK.
[2024-01-02 19:52:39,211] [INFO] [RANK 0]  > number of parameters on model parallel rank 0: 18291033280
INFO:sat:[RANK 0]  > number of parameters on model parallel rank 0: 18291033280
[2024-01-02 19:52:40 +0000] [10227] [CRITICAL] WORKER TIMEOUT (pid:10228)
[2024-01-02 19:52:40 +0000] [10228] [INFO] Worker exiting (pid: 10228)
[2024-01-02 19:52:41 +0000] [10227] [ERROR] Worker (pid:10228) exited with code 1
[2024-01-02 19:52:41 +0000] [10227] [ERROR] Worker (pid:10228) exited with code 1.
[2024-01-02 19:52:41 +0000] [10508] [INFO] Booting worker with pid: 10508
[2024-01-02 19:53:19 +0000] [10227] [INFO] Handling signal: int
[2024-01-02 19:53:19 +0000] [10508] [INFO] Worker exiting (pid: 10508)
[2024-01-02 19:53:20 +0000] [10227] [INFO] Shutting down: Master
[2024-01-02 19:56:08 +0000] [10951] [INFO] Starting gunicorn 21.2.0
[2024-01-02 19:56:08 +0000] [10951] [INFO] Listening at: http://0.0.0.0:8000 (10951)
[2024-01-02 19:56:08 +0000] [10951] [INFO] Using worker: sync
[2024-01-02 19:56:08 +0000] [10952] [INFO] Booting worker with pid: 10952
[2024-01-02 19:59:10 +0000] [10951] [INFO] Handling signal: int
[2024-01-02 19:59:10 +0000] [10952] [INFO] Worker exiting (pid: 10952)
[2024-01-02 19:59:11 +0000] [10951] [INFO] Shutting down: Master
[2024-01-02 20:03:41 +0000] [11766] [INFO] Starting gunicorn 21.2.0
[2024-01-02 20:03:41 +0000] [11766] [INFO] Listening at: http://0.0.0.0:8000 (11766)
[2024-01-02 20:03:41 +0000] [11766] [INFO] Using worker: sync
[2024-01-02 20:03:41 +0000] [11767] [INFO] Booting worker with pid: 11767
[2024-01-02 20:14:16 +0000] [11766] [INFO] Handling signal: int
[2024-01-02 20:14:16 +0000] [11767] [INFO] Worker exiting (pid: 11767)
[2024-01-02 20:14:17 +0000] [11766] [INFO] Shutting down: Master
[2024-01-02 20:14:19 +0000] [14643] [INFO] Starting gunicorn 21.2.0
[2024-01-02 20:14:19 +0000] [14643] [INFO] Listening at: http://0.0.0.0:8000 (14643)
[2024-01-02 20:14:19 +0000] [14643] [INFO] Using worker: sync
[2024-01-02 20:14:19 +0000] [14644] [INFO] Booting worker with pid: 14644
[2024-01-02 20:14:20 +0000] [14643] [INFO] Handling signal: int
[2024-01-02 20:14:20 +0000] [14644] [INFO] Worker exiting (pid: 14644)
[2024-01-02 20:14:20 +0000] [14643] [INFO] Shutting down: Master
[2024-01-02 20:15:03 +0000] [14728] [INFO] Starting gunicorn 21.2.0
[2024-01-02 20:15:03 +0000] [14728] [INFO] Listening at: http://0.0.0.0:8000 (14728)
[2024-01-02 20:15:03 +0000] [14728] [INFO] Using worker: sync
[2024-01-02 20:15:03 +0000] [14736] [INFO] Booting worker with pid: 14736
[2024-01-02 20:16:48 +0000] [14728] [INFO] Handling signal: int
[2024-01-02 20:16:49 +0000] [14736] [INFO] Worker exiting (pid: 14736)
[2024-01-02 20:16:50 +0000] [14728] [INFO] Shutting down: Master
[2024-01-02 20:21:22 +0000] [15471] [INFO] Starting gunicorn 21.2.0
[2024-01-02 20:21:22 +0000] [15471] [INFO] Listening at: http://0.0.0.0:8000 (15471)
[2024-01-02 20:21:22 +0000] [15471] [INFO] Using worker: sync
[2024-01-02 20:21:22 +0000] [15472] [INFO] Booting worker with pid: 15472
[2024-01-02 20:23:27,341] [INFO] building CogAgentModel model ...
[2024-01-02 20:23:27,344] [INFO] [RANK 0] > initializing model parallel with size 1
[2024-01-02 20:23:27,344] [INFO] [RANK 0] You didn't pass in LOCAL_WORLD_SIZE environment variable. We use the guessed LOCAL_WORLD_SIZE=1. If this is wrong, please pass the LOCAL_WORLD_SIZE manually.
[2024-01-02 20:23:27,345] [INFO] [RANK 0] You are using model-only mode.
For torch.distributed users or loading model parallel models, set environment variables RANK, WORLD_SIZE and LOCAL_RANK.
[2024-01-02 20:23:56,356] [INFO] [RANK 0]  > number of parameters on model parallel rank 0: 18291033280
INFO:sat:[RANK 0]  > number of parameters on model parallel rank 0: 18291033280
[2024-01-02 20:23:57 +0000] [15471] [CRITICAL] WORKER TIMEOUT (pid:15472)
[2024-01-02 20:23:57 +0000] [15472] [INFO] Worker exiting (pid: 15472)
[2024-01-02 20:23:58 +0000] [15471] [ERROR] Worker (pid:15472) exited with code 1
[2024-01-02 20:23:58 +0000] [15471] [ERROR] Worker (pid:15472) exited with code 1.
[2024-01-02 20:23:58 +0000] [15740] [INFO] Booting worker with pid: 15740
[2024-01-02 20:25:46,764] ERROR in app: Exception on /infer [GET]
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 1455, in wsgi_app
    response = self.full_dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 869, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 867, in full_dispatch_request
    rv = self.dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 852, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
  File "/home/onlyvedansh/cogagent2/finale.py", line 166, in infer
    answerdict=predictor.predict(string_data,imagepath)
NameError: name 'predictor' is not defined. Did you mean: 'Predictor'?
[2024-01-02 20:26:24,075] [INFO] building CogAgentModel model ...
[2024-01-02 20:26:24,078] [INFO] [RANK 0] > initializing model parallel with size 1
[2024-01-02 20:26:24,078] [INFO] [RANK 0] You didn't pass in LOCAL_WORLD_SIZE environment variable. We use the guessed LOCAL_WORLD_SIZE=1. If this is wrong, please pass the LOCAL_WORLD_SIZE manually.
[2024-01-02 20:26:24,078] [INFO] [RANK 0] You are using model-only mode.
For torch.distributed users or loading model parallel models, set environment variables RANK, WORLD_SIZE and LOCAL_RANK.
[2024-01-02 20:26:53,071] [INFO] [RANK 0]  > number of parameters on model parallel rank 0: 18291033280
INFO:sat:[RANK 0]  > number of parameters on model parallel rank 0: 18291033280
[2024-01-02 20:26:54 +0000] [15471] [CRITICAL] WORKER TIMEOUT (pid:15740)
[2024-01-02 20:26:54 +0000] [15740] [INFO] Worker exiting (pid: 15740)
[2024-01-02 20:26:55 +0000] [15471] [ERROR] Worker (pid:15740) exited with code 1
[2024-01-02 20:26:55 +0000] [15471] [ERROR] Worker (pid:15740) exited with code 1.
[2024-01-02 20:26:55 +0000] [16103] [INFO] Booting worker with pid: 16103
[2024-01-02 20:27:20 +0000] [15471] [INFO] Handling signal: int
[2024-01-02 20:27:20 +0000] [16103] [INFO] Worker exiting (pid: 16103)
[2024-01-02 20:27:21 +0000] [15471] [INFO] Shutting down: Master
[2024-01-02 20:27:58 +0000] [16246] [INFO] Starting gunicorn 21.2.0
[2024-01-02 20:27:58 +0000] [16246] [INFO] Listening at: http://0.0.0.0:8000 (16246)
[2024-01-02 20:27:58 +0000] [16246] [INFO] Using worker: sync
[2024-01-02 20:27:58 +0000] [16247] [INFO] Booting worker with pid: 16247
[2024-01-02 20:28:16,926] [INFO] building CogAgentModel model ...
[2024-01-02 20:28:16,928] [INFO] [RANK 0] > initializing model parallel with size 1
[2024-01-02 20:28:16,928] [INFO] [RANK 0] You didn't pass in LOCAL_WORLD_SIZE environment variable. We use the guessed LOCAL_WORLD_SIZE=1. If this is wrong, please pass the LOCAL_WORLD_SIZE manually.
[2024-01-02 20:28:16,929] [INFO] [RANK 0] You are using model-only mode.
For torch.distributed users or loading model parallel models, set environment variables RANK, WORLD_SIZE and LOCAL_RANK.
[2024-01-02 20:28:45,976] [INFO] [RANK 0]  > number of parameters on model parallel rank 0: 18291033280
INFO:sat:[RANK 0]  > number of parameters on model parallel rank 0: 18291033280
[2024-01-02 20:28:47 +0000] [16246] [CRITICAL] WORKER TIMEOUT (pid:16247)
[2024-01-02 20:28:47 +0000] [16247] [INFO] Worker exiting (pid: 16247)
[2024-01-02 20:28:48 +0000] [16246] [ERROR] Worker (pid:16247) exited with code 1
[2024-01-02 20:28:48 +0000] [16246] [ERROR] Worker (pid:16247) exited with code 1.
[2024-01-02 20:28:48 +0000] [16416] [INFO] Booting worker with pid: 16416
[2024-01-02 20:29:25 +0000] [16246] [INFO] Handling signal: int
[2024-01-02 20:29:25 +0000] [16416] [INFO] Worker exiting (pid: 16416)
[2024-01-02 20:29:26 +0000] [16246] [INFO] Shutting down: Master
[2024-01-02 20:31:53 +0000] [16789] [INFO] Starting gunicorn 21.2.0
[2024-01-02 20:31:53 +0000] [16789] [INFO] Listening at: http://0.0.0.0:8000 (16789)
[2024-01-02 20:31:53 +0000] [16789] [INFO] Using worker: sync
[2024-01-02 20:31:53 +0000] [16790] [INFO] Booting worker with pid: 16790
[2024-01-02 20:32:15,654] [INFO] building CogAgentModel model ...
[2024-01-02 20:32:15,657] [INFO] [RANK 0] > initializing model parallel with size 1
[2024-01-02 20:32:15,657] [INFO] [RANK 0] You didn't pass in LOCAL_WORLD_SIZE environment variable. We use the guessed LOCAL_WORLD_SIZE=1. If this is wrong, please pass the LOCAL_WORLD_SIZE manually.
[2024-01-02 20:32:15,658] [INFO] [RANK 0] You are using model-only mode.
For torch.distributed users or loading model parallel models, set environment variables RANK, WORLD_SIZE and LOCAL_RANK.
[2024-01-02 20:32:44,595] [INFO] [RANK 0]  > number of parameters on model parallel rank 0: 18291033280
INFO:sat:[RANK 0]  > number of parameters on model parallel rank 0: 18291033280
[2024-01-02 20:32:46 +0000] [16789] [CRITICAL] WORKER TIMEOUT (pid:16790)
[2024-01-02 20:32:46 +0000] [16790] [INFO] Worker exiting (pid: 16790)
[2024-01-02 20:32:47 +0000] [16789] [ERROR] Worker (pid:16790) exited with code 1
[2024-01-02 20:32:47 +0000] [16789] [ERROR] Worker (pid:16790) exited with code 1.
[2024-01-02 20:32:47 +0000] [16942] [INFO] Booting worker with pid: 16942
[2024-01-02 20:34:24,853] ERROR in app: Exception on /infer [GET]
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 1455, in wsgi_app
    response = self.full_dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 869, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 867, in full_dispatch_request
    rv = self.dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 852, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
  File "/home/onlyvedansh/cogagent2/finale.py", line 166, in infer
    answerdict=predictor.predict(string_data,imagepath)
NameError: name 'predictor' is not defined. Did you mean: 'Predictor'?
[2024-01-02 20:35:53 +0000] [16789] [INFO] Handling signal: int
[2024-01-02 20:35:53 +0000] [16942] [INFO] Worker exiting (pid: 16942)
[2024-01-02 20:35:54 +0000] [16789] [INFO] Shutting down: Master
[2024-01-02 20:41:21 +0000] [19716] [INFO] Starting gunicorn 21.2.0
[2024-01-02 20:41:21 +0000] [19716] [INFO] Listening at: http://0.0.0.0:8000 (19716)
[2024-01-02 20:41:21 +0000] [19716] [INFO] Using worker: sync
[2024-01-02 20:41:21 +0000] [19717] [INFO] Booting worker with pid: 19717
[2024-01-02 20:41:33,114] [INFO] building CogAgentModel model ...
[2024-01-02 20:41:33,117] [INFO] [RANK 0] > initializing model parallel with size 1
[2024-01-02 20:41:33,117] [INFO] [RANK 0] You didn't pass in LOCAL_WORLD_SIZE environment variable. We use the guessed LOCAL_WORLD_SIZE=1. If this is wrong, please pass the LOCAL_WORLD_SIZE manually.
[2024-01-02 20:41:33,118] [INFO] [RANK 0] You are using model-only mode.
For torch.distributed users or loading model parallel models, set environment variables RANK, WORLD_SIZE and LOCAL_RANK.
[2024-01-02 20:42:02,123] [INFO] [RANK 0]  > number of parameters on model parallel rank 0: 18291033280
INFO:sat:[RANK 0]  > number of parameters on model parallel rank 0: 18291033280
[2024-01-02 20:42:04 +0000] [19716] [CRITICAL] WORKER TIMEOUT (pid:19717)
[2024-01-02 20:42:04 +0000] [19717] [INFO] Worker exiting (pid: 19717)
[2024-01-02 20:42:05 +0000] [19716] [ERROR] Worker (pid:19717) exited with code 1
[2024-01-02 20:42:05 +0000] [19716] [ERROR] Worker (pid:19717) exited with code 1.
[2024-01-02 20:42:05 +0000] [19855] [INFO] Booting worker with pid: 19855
[2024-01-02 20:44:38,477] ERROR in app: Exception on /infer [GET]
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 1455, in wsgi_app
    response = self.full_dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 869, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 867, in full_dispatch_request
    rv = self.dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 852, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
  File "/home/onlyvedansh/cogagent2/finale.py", line 167, in infer
    answerdict=app.predictor.predict(string_data,imagepath)
AttributeError: 'NoneType' object has no attribute 'predict'
[2024-01-02 20:44:46 +0000] [19716] [INFO] Handling signal: int
[2024-01-02 20:44:46 +0000] [19855] [INFO] Worker exiting (pid: 19855)
[2024-01-02 20:44:47 +0000] [19716] [INFO] Shutting down: Master
[2024-01-02 21:28:45 +0000] [4225] [INFO] Starting gunicorn 21.2.0
[2024-01-02 21:28:45 +0000] [4225] [INFO] Listening at: http://0.0.0.0:8000 (4225)
[2024-01-02 21:28:45 +0000] [4225] [INFO] Using worker: sync
[2024-01-02 21:28:45 +0000] [4226] [INFO] Booting worker with pid: 4226
[2024-01-02 21:29:05,005] [INFO] building CogAgentModel model ...
[2024-01-02 21:29:05,011] [INFO] [RANK 0] > initializing model parallel with size 1
[2024-01-02 21:29:05,012] [INFO] [RANK 0] You didn't pass in LOCAL_WORLD_SIZE environment variable. We use the guessed LOCAL_WORLD_SIZE=1. If this is wrong, please pass the LOCAL_WORLD_SIZE manually.
[2024-01-02 21:29:05,013] [INFO] [RANK 0] You are using model-only mode.
For torch.distributed users or loading model parallel models, set environment variables RANK, WORLD_SIZE and LOCAL_RANK.
[2024-01-02 21:29:34,219] [INFO] [RANK 0]  > number of parameters on model parallel rank 0: 18291033280
INFO:sat:[RANK 0]  > number of parameters on model parallel rank 0: 18291033280
[2024-01-02 21:29:39,595] [INFO] [RANK 0] global rank 0 is loading checkpoint /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
INFO:sat:[RANK 0] global rank 0 is loading checkpoint /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
[2024-01-02 21:31:29,303] [INFO] [RANK 0] > successfully loaded /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
INFO:sat:[RANK 0] > successfully loaded /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
--- Logging error ---
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 1100, in emit
    msg = self.format(record)
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 943, in format
    return fmt.format(record)
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 678, in format
    record.message = record.getMessage()
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 368, in getMessage
    msg = msg % self.args
TypeError: not all arguments converted during string formatting
Call stack:
  File "/opt/conda/bin/gunicorn", line 8, in <module>
    sys.exit(run())
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py", line 67, in run
    WSGIApplication("%(prog)s [OPTIONS] [APP_MODULE]").run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/app/base.py", line 236, in run
    super().run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/app/base.py", line 72, in run
    Arbiter(self).run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 202, in run
    self.manage_workers()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 571, in manage_workers
    self.spawn_workers()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 642, in spawn_workers
    self.spawn_worker()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 609, in spawn_worker
    worker.init_process()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/base.py", line 142, in init_process
    self.run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 126, in run
    self.run_for_one(timeout)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 70, in run_for_one
    self.accept(listener)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 32, in accept
    self.handle(listener, client, addr)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 135, in handle
    self.handle_request(listener, req, client, addr)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 178, in handle_request
    respiter = self.wsgi(environ, resp.start_response)
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 1478, in __call__
    return self.wsgi_app(environ, start_response)
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 1455, in wsgi_app
    response = self.full_dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 867, in full_dispatch_request
    rv = self.dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 852, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
  File "/home/onlyvedansh/cogagent2/finale.py", line 154, in initiate
    app.predictor=Predictor()
  File "/home/onlyvedansh/cogagent2/finale.py", line 94, in __init__
    logger.error("[Language processor version]:", self.language_processor_version)
Message: '[Language processor version]:'
Arguments: ('chat',)
ERROR:finale:Exception on /initiate [GET]
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 1455, in wsgi_app
    response = self.full_dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 870, in full_dispatch_request
    return self.finalize_request(rv)
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 889, in finalize_request
    response = self.make_response(rv)
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 1161, in make_response
    raise TypeError(
TypeError: The view function for 'initiate' did not return a valid response. The function either returned None or ended without a return statement.
ERROR:finale:click on images
ERROR:finale:Exception on /infer [GET]
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 1455, in wsgi_app
    response = self.full_dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 869, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 867, in full_dispatch_request
    rv = self.dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 852, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
  File "/home/onlyvedansh/cogagent2/finale.py", line 167, in infer
    answerdict=app.predictor.predict(string_data,imagepath)
  File "/home/onlyvedansh/cogagent2/finale.py", line 119, in predict
    self.response, self.history, self.cache_image = chat(
  File "/home/onlyvedansh/cogagent2/utils/utils/chat.py", line 53, in chat
    (torch_image, pil_img, cross_image) = process_image(image_path, img_processor, cross_img_processor, image)
  File "/home/onlyvedansh/cogagent2/utils/utils/chat.py", line 28, in process_image
    image = Image.open(image_path)
  File "/opt/conda/lib/python3.10/site-packages/PIL/Image.py", line 3243, in open
    fp = builtins.open(filename, "rb")
FileNotFoundError: [Errno 2] No such file or directory: '/home/onlyvedansh/cogagent2/utils/utils/utils/utils/a.jpg'
[2024-01-02 21:31:37 +0000] [4225] [INFO] Handling signal: int
[2024-01-02 21:31:37 +0000] [4226] [INFO] Worker exiting (pid: 4226)
[2024-01-02 21:31:39 +0000] [4225] [INFO] Shutting down: Master
