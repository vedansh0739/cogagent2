[2024-01-02 17:25:44 +0000] [5547] [INFO] Starting gunicorn 21.2.0
[2024-01-02 17:25:44 +0000] [5547] [INFO] Listening at: http://0.0.0.0:8000 (5547)
[2024-01-02 17:25:44 +0000] [5547] [INFO] Using worker: sync
[2024-01-02 17:25:44 +0000] [5548] [INFO] Booting worker with pid: 5548
[2024-01-02 17:25:48 +0000] [5547] [INFO] Handling signal: int
[2024-01-02 17:25:49 +0000] [5548] [INFO] Worker exiting (pid: 5548)
[2024-01-02 17:25:49 +0000] [5547] [INFO] Shutting down: Master
[2024-01-02 17:27:33 +0000] [5779] [INFO] Starting gunicorn 21.2.0
[2024-01-02 17:27:33 +0000] [5779] [INFO] Listening at: http://0.0.0.0:8000 (5779)
[2024-01-02 17:27:33 +0000] [5779] [INFO] Using worker: sync
[2024-01-02 17:27:33 +0000] [5780] [INFO] Booting worker with pid: 5780
[2024-01-02 17:28:18 +0000] [5779] [INFO] Handling signal: int
[2024-01-02 17:28:18 +0000] [5780] [INFO] Worker exiting (pid: 5780)
[2024-01-02 17:28:19 +0000] [5779] [INFO] Shutting down: Master
[2024-01-02 17:30:23 +0000] [6121] [INFO] Starting gunicorn 21.2.0
[2024-01-02 17:30:23 +0000] [6121] [INFO] Listening at: http://0.0.0.0:8000 (6121)
[2024-01-02 17:30:23 +0000] [6121] [INFO] Using worker: sync
[2024-01-02 17:30:23 +0000] [6122] [INFO] Booting worker with pid: 6122
[2024-01-02 17:31:02 +0000] [6121] [INFO] Handling signal: int
[2024-01-02 17:31:02 +0000] [6122] [INFO] Worker exiting (pid: 6122)
[2024-01-02 17:31:03 +0000] [6121] [INFO] Shutting down: Master
[2024-01-02 19:50:26 +0000] [10227] [INFO] Starting gunicorn 21.2.0
[2024-01-02 19:50:26 +0000] [10227] [INFO] Listening at: http://0.0.0.0:8000 (10227)
[2024-01-02 19:50:26 +0000] [10227] [INFO] Using worker: sync
[2024-01-02 19:50:26 +0000] [10228] [INFO] Booting worker with pid: 10228
[2024-01-02 19:52:10,212] [INFO] building CogAgentModel model ...
[2024-01-02 19:52:10,215] [INFO] [RANK 0] > initializing model parallel with size 1
[2024-01-02 19:52:10,215] [INFO] [RANK 0] You didn't pass in LOCAL_WORLD_SIZE environment variable. We use the guessed LOCAL_WORLD_SIZE=1. If this is wrong, please pass the LOCAL_WORLD_SIZE manually.
[2024-01-02 19:52:10,216] [INFO] [RANK 0] You are using model-only mode.
For torch.distributed users or loading model parallel models, set environment variables RANK, WORLD_SIZE and LOCAL_RANK.
[2024-01-02 19:52:39,211] [INFO] [RANK 0]  > number of parameters on model parallel rank 0: 18291033280
INFO:sat:[RANK 0]  > number of parameters on model parallel rank 0: 18291033280
[2024-01-02 19:52:40 +0000] [10227] [CRITICAL] WORKER TIMEOUT (pid:10228)
[2024-01-02 19:52:40 +0000] [10228] [INFO] Worker exiting (pid: 10228)
[2024-01-02 19:52:41 +0000] [10227] [ERROR] Worker (pid:10228) exited with code 1
[2024-01-02 19:52:41 +0000] [10227] [ERROR] Worker (pid:10228) exited with code 1.
[2024-01-02 19:52:41 +0000] [10508] [INFO] Booting worker with pid: 10508
[2024-01-02 19:53:19 +0000] [10227] [INFO] Handling signal: int
[2024-01-02 19:53:19 +0000] [10508] [INFO] Worker exiting (pid: 10508)
[2024-01-02 19:53:20 +0000] [10227] [INFO] Shutting down: Master
[2024-01-02 19:56:08 +0000] [10951] [INFO] Starting gunicorn 21.2.0
[2024-01-02 19:56:08 +0000] [10951] [INFO] Listening at: http://0.0.0.0:8000 (10951)
[2024-01-02 19:56:08 +0000] [10951] [INFO] Using worker: sync
[2024-01-02 19:56:08 +0000] [10952] [INFO] Booting worker with pid: 10952
[2024-01-02 19:59:10 +0000] [10951] [INFO] Handling signal: int
[2024-01-02 19:59:10 +0000] [10952] [INFO] Worker exiting (pid: 10952)
[2024-01-02 19:59:11 +0000] [10951] [INFO] Shutting down: Master
[2024-01-02 20:03:41 +0000] [11766] [INFO] Starting gunicorn 21.2.0
[2024-01-02 20:03:41 +0000] [11766] [INFO] Listening at: http://0.0.0.0:8000 (11766)
[2024-01-02 20:03:41 +0000] [11766] [INFO] Using worker: sync
[2024-01-02 20:03:41 +0000] [11767] [INFO] Booting worker with pid: 11767
[2024-01-02 20:14:16 +0000] [11766] [INFO] Handling signal: int
[2024-01-02 20:14:16 +0000] [11767] [INFO] Worker exiting (pid: 11767)
[2024-01-02 20:14:17 +0000] [11766] [INFO] Shutting down: Master
[2024-01-02 20:14:19 +0000] [14643] [INFO] Starting gunicorn 21.2.0
[2024-01-02 20:14:19 +0000] [14643] [INFO] Listening at: http://0.0.0.0:8000 (14643)
[2024-01-02 20:14:19 +0000] [14643] [INFO] Using worker: sync
[2024-01-02 20:14:19 +0000] [14644] [INFO] Booting worker with pid: 14644
[2024-01-02 20:14:20 +0000] [14643] [INFO] Handling signal: int
[2024-01-02 20:14:20 +0000] [14644] [INFO] Worker exiting (pid: 14644)
[2024-01-02 20:14:20 +0000] [14643] [INFO] Shutting down: Master
[2024-01-02 20:15:03 +0000] [14728] [INFO] Starting gunicorn 21.2.0
[2024-01-02 20:15:03 +0000] [14728] [INFO] Listening at: http://0.0.0.0:8000 (14728)
[2024-01-02 20:15:03 +0000] [14728] [INFO] Using worker: sync
[2024-01-02 20:15:03 +0000] [14736] [INFO] Booting worker with pid: 14736
[2024-01-02 20:16:48 +0000] [14728] [INFO] Handling signal: int
[2024-01-02 20:16:49 +0000] [14736] [INFO] Worker exiting (pid: 14736)
[2024-01-02 20:16:50 +0000] [14728] [INFO] Shutting down: Master
[2024-01-02 20:21:22 +0000] [15471] [INFO] Starting gunicorn 21.2.0
[2024-01-02 20:21:22 +0000] [15471] [INFO] Listening at: http://0.0.0.0:8000 (15471)
[2024-01-02 20:21:22 +0000] [15471] [INFO] Using worker: sync
[2024-01-02 20:21:22 +0000] [15472] [INFO] Booting worker with pid: 15472
[2024-01-02 20:23:27,341] [INFO] building CogAgentModel model ...
[2024-01-02 20:23:27,344] [INFO] [RANK 0] > initializing model parallel with size 1
[2024-01-02 20:23:27,344] [INFO] [RANK 0] You didn't pass in LOCAL_WORLD_SIZE environment variable. We use the guessed LOCAL_WORLD_SIZE=1. If this is wrong, please pass the LOCAL_WORLD_SIZE manually.
[2024-01-02 20:23:27,345] [INFO] [RANK 0] You are using model-only mode.
For torch.distributed users or loading model parallel models, set environment variables RANK, WORLD_SIZE and LOCAL_RANK.
[2024-01-02 20:23:56,356] [INFO] [RANK 0]  > number of parameters on model parallel rank 0: 18291033280
INFO:sat:[RANK 0]  > number of parameters on model parallel rank 0: 18291033280
[2024-01-02 20:23:57 +0000] [15471] [CRITICAL] WORKER TIMEOUT (pid:15472)
[2024-01-02 20:23:57 +0000] [15472] [INFO] Worker exiting (pid: 15472)
[2024-01-02 20:23:58 +0000] [15471] [ERROR] Worker (pid:15472) exited with code 1
[2024-01-02 20:23:58 +0000] [15471] [ERROR] Worker (pid:15472) exited with code 1.
[2024-01-02 20:23:58 +0000] [15740] [INFO] Booting worker with pid: 15740
[2024-01-02 20:25:46,764] ERROR in app: Exception on /infer [GET]
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 1455, in wsgi_app
    response = self.full_dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 869, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 867, in full_dispatch_request
    rv = self.dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 852, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
  File "/home/onlyvedansh/cogagent2/finale.py", line 166, in infer
    answerdict=predictor.predict(string_data,imagepath)
NameError: name 'predictor' is not defined. Did you mean: 'Predictor'?
[2024-01-02 20:26:24,075] [INFO] building CogAgentModel model ...
[2024-01-02 20:26:24,078] [INFO] [RANK 0] > initializing model parallel with size 1
[2024-01-02 20:26:24,078] [INFO] [RANK 0] You didn't pass in LOCAL_WORLD_SIZE environment variable. We use the guessed LOCAL_WORLD_SIZE=1. If this is wrong, please pass the LOCAL_WORLD_SIZE manually.
[2024-01-02 20:26:24,078] [INFO] [RANK 0] You are using model-only mode.
For torch.distributed users or loading model parallel models, set environment variables RANK, WORLD_SIZE and LOCAL_RANK.
[2024-01-02 20:26:53,071] [INFO] [RANK 0]  > number of parameters on model parallel rank 0: 18291033280
INFO:sat:[RANK 0]  > number of parameters on model parallel rank 0: 18291033280
[2024-01-02 20:26:54 +0000] [15471] [CRITICAL] WORKER TIMEOUT (pid:15740)
[2024-01-02 20:26:54 +0000] [15740] [INFO] Worker exiting (pid: 15740)
[2024-01-02 20:26:55 +0000] [15471] [ERROR] Worker (pid:15740) exited with code 1
[2024-01-02 20:26:55 +0000] [15471] [ERROR] Worker (pid:15740) exited with code 1.
[2024-01-02 20:26:55 +0000] [16103] [INFO] Booting worker with pid: 16103
[2024-01-02 20:27:20 +0000] [15471] [INFO] Handling signal: int
[2024-01-02 20:27:20 +0000] [16103] [INFO] Worker exiting (pid: 16103)
[2024-01-02 20:27:21 +0000] [15471] [INFO] Shutting down: Master
[2024-01-02 20:27:58 +0000] [16246] [INFO] Starting gunicorn 21.2.0
[2024-01-02 20:27:58 +0000] [16246] [INFO] Listening at: http://0.0.0.0:8000 (16246)
[2024-01-02 20:27:58 +0000] [16246] [INFO] Using worker: sync
[2024-01-02 20:27:58 +0000] [16247] [INFO] Booting worker with pid: 16247
[2024-01-02 20:28:16,926] [INFO] building CogAgentModel model ...
[2024-01-02 20:28:16,928] [INFO] [RANK 0] > initializing model parallel with size 1
[2024-01-02 20:28:16,928] [INFO] [RANK 0] You didn't pass in LOCAL_WORLD_SIZE environment variable. We use the guessed LOCAL_WORLD_SIZE=1. If this is wrong, please pass the LOCAL_WORLD_SIZE manually.
[2024-01-02 20:28:16,929] [INFO] [RANK 0] You are using model-only mode.
For torch.distributed users or loading model parallel models, set environment variables RANK, WORLD_SIZE and LOCAL_RANK.
[2024-01-02 20:28:45,976] [INFO] [RANK 0]  > number of parameters on model parallel rank 0: 18291033280
INFO:sat:[RANK 0]  > number of parameters on model parallel rank 0: 18291033280
[2024-01-02 20:28:47 +0000] [16246] [CRITICAL] WORKER TIMEOUT (pid:16247)
[2024-01-02 20:28:47 +0000] [16247] [INFO] Worker exiting (pid: 16247)
[2024-01-02 20:28:48 +0000] [16246] [ERROR] Worker (pid:16247) exited with code 1
[2024-01-02 20:28:48 +0000] [16246] [ERROR] Worker (pid:16247) exited with code 1.
[2024-01-02 20:28:48 +0000] [16416] [INFO] Booting worker with pid: 16416
[2024-01-02 20:29:25 +0000] [16246] [INFO] Handling signal: int
[2024-01-02 20:29:25 +0000] [16416] [INFO] Worker exiting (pid: 16416)
[2024-01-02 20:29:26 +0000] [16246] [INFO] Shutting down: Master
[2024-01-02 20:31:53 +0000] [16789] [INFO] Starting gunicorn 21.2.0
[2024-01-02 20:31:53 +0000] [16789] [INFO] Listening at: http://0.0.0.0:8000 (16789)
[2024-01-02 20:31:53 +0000] [16789] [INFO] Using worker: sync
[2024-01-02 20:31:53 +0000] [16790] [INFO] Booting worker with pid: 16790
[2024-01-02 20:32:15,654] [INFO] building CogAgentModel model ...
[2024-01-02 20:32:15,657] [INFO] [RANK 0] > initializing model parallel with size 1
[2024-01-02 20:32:15,657] [INFO] [RANK 0] You didn't pass in LOCAL_WORLD_SIZE environment variable. We use the guessed LOCAL_WORLD_SIZE=1. If this is wrong, please pass the LOCAL_WORLD_SIZE manually.
[2024-01-02 20:32:15,658] [INFO] [RANK 0] You are using model-only mode.
For torch.distributed users or loading model parallel models, set environment variables RANK, WORLD_SIZE and LOCAL_RANK.
[2024-01-02 20:32:44,595] [INFO] [RANK 0]  > number of parameters on model parallel rank 0: 18291033280
INFO:sat:[RANK 0]  > number of parameters on model parallel rank 0: 18291033280
[2024-01-02 20:32:46 +0000] [16789] [CRITICAL] WORKER TIMEOUT (pid:16790)
[2024-01-02 20:32:46 +0000] [16790] [INFO] Worker exiting (pid: 16790)
[2024-01-02 20:32:47 +0000] [16789] [ERROR] Worker (pid:16790) exited with code 1
[2024-01-02 20:32:47 +0000] [16789] [ERROR] Worker (pid:16790) exited with code 1.
[2024-01-02 20:32:47 +0000] [16942] [INFO] Booting worker with pid: 16942
[2024-01-02 20:34:24,853] ERROR in app: Exception on /infer [GET]
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 1455, in wsgi_app
    response = self.full_dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 869, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 867, in full_dispatch_request
    rv = self.dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 852, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
  File "/home/onlyvedansh/cogagent2/finale.py", line 166, in infer
    answerdict=predictor.predict(string_data,imagepath)
NameError: name 'predictor' is not defined. Did you mean: 'Predictor'?
[2024-01-02 20:35:53 +0000] [16789] [INFO] Handling signal: int
[2024-01-02 20:35:53 +0000] [16942] [INFO] Worker exiting (pid: 16942)
[2024-01-02 20:35:54 +0000] [16789] [INFO] Shutting down: Master
[2024-01-02 20:41:21 +0000] [19716] [INFO] Starting gunicorn 21.2.0
[2024-01-02 20:41:21 +0000] [19716] [INFO] Listening at: http://0.0.0.0:8000 (19716)
[2024-01-02 20:41:21 +0000] [19716] [INFO] Using worker: sync
[2024-01-02 20:41:21 +0000] [19717] [INFO] Booting worker with pid: 19717
[2024-01-02 20:41:33,114] [INFO] building CogAgentModel model ...
[2024-01-02 20:41:33,117] [INFO] [RANK 0] > initializing model parallel with size 1
[2024-01-02 20:41:33,117] [INFO] [RANK 0] You didn't pass in LOCAL_WORLD_SIZE environment variable. We use the guessed LOCAL_WORLD_SIZE=1. If this is wrong, please pass the LOCAL_WORLD_SIZE manually.
[2024-01-02 20:41:33,118] [INFO] [RANK 0] You are using model-only mode.
For torch.distributed users or loading model parallel models, set environment variables RANK, WORLD_SIZE and LOCAL_RANK.
[2024-01-02 20:42:02,123] [INFO] [RANK 0]  > number of parameters on model parallel rank 0: 18291033280
INFO:sat:[RANK 0]  > number of parameters on model parallel rank 0: 18291033280
[2024-01-02 20:42:04 +0000] [19716] [CRITICAL] WORKER TIMEOUT (pid:19717)
[2024-01-02 20:42:04 +0000] [19717] [INFO] Worker exiting (pid: 19717)
[2024-01-02 20:42:05 +0000] [19716] [ERROR] Worker (pid:19717) exited with code 1
[2024-01-02 20:42:05 +0000] [19716] [ERROR] Worker (pid:19717) exited with code 1.
[2024-01-02 20:42:05 +0000] [19855] [INFO] Booting worker with pid: 19855
[2024-01-02 20:44:38,477] ERROR in app: Exception on /infer [GET]
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 1455, in wsgi_app
    response = self.full_dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 869, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 867, in full_dispatch_request
    rv = self.dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 852, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
  File "/home/onlyvedansh/cogagent2/finale.py", line 167, in infer
    answerdict=app.predictor.predict(string_data,imagepath)
AttributeError: 'NoneType' object has no attribute 'predict'
[2024-01-02 20:44:46 +0000] [19716] [INFO] Handling signal: int
[2024-01-02 20:44:46 +0000] [19855] [INFO] Worker exiting (pid: 19855)
[2024-01-02 20:44:47 +0000] [19716] [INFO] Shutting down: Master
[2024-01-02 21:28:45 +0000] [4225] [INFO] Starting gunicorn 21.2.0
[2024-01-02 21:28:45 +0000] [4225] [INFO] Listening at: http://0.0.0.0:8000 (4225)
[2024-01-02 21:28:45 +0000] [4225] [INFO] Using worker: sync
[2024-01-02 21:28:45 +0000] [4226] [INFO] Booting worker with pid: 4226
[2024-01-02 21:29:05,005] [INFO] building CogAgentModel model ...
[2024-01-02 21:29:05,011] [INFO] [RANK 0] > initializing model parallel with size 1
[2024-01-02 21:29:05,012] [INFO] [RANK 0] You didn't pass in LOCAL_WORLD_SIZE environment variable. We use the guessed LOCAL_WORLD_SIZE=1. If this is wrong, please pass the LOCAL_WORLD_SIZE manually.
[2024-01-02 21:29:05,013] [INFO] [RANK 0] You are using model-only mode.
For torch.distributed users or loading model parallel models, set environment variables RANK, WORLD_SIZE and LOCAL_RANK.
[2024-01-02 21:29:34,219] [INFO] [RANK 0]  > number of parameters on model parallel rank 0: 18291033280
INFO:sat:[RANK 0]  > number of parameters on model parallel rank 0: 18291033280
[2024-01-02 21:29:39,595] [INFO] [RANK 0] global rank 0 is loading checkpoint /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
INFO:sat:[RANK 0] global rank 0 is loading checkpoint /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
[2024-01-02 21:31:29,303] [INFO] [RANK 0] > successfully loaded /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
INFO:sat:[RANK 0] > successfully loaded /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
--- Logging error ---
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 1100, in emit
    msg = self.format(record)
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 943, in format
    return fmt.format(record)
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 678, in format
    record.message = record.getMessage()
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 368, in getMessage
    msg = msg % self.args
TypeError: not all arguments converted during string formatting
Call stack:
  File "/opt/conda/bin/gunicorn", line 8, in <module>
    sys.exit(run())
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py", line 67, in run
    WSGIApplication("%(prog)s [OPTIONS] [APP_MODULE]").run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/app/base.py", line 236, in run
    super().run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/app/base.py", line 72, in run
    Arbiter(self).run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 202, in run
    self.manage_workers()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 571, in manage_workers
    self.spawn_workers()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 642, in spawn_workers
    self.spawn_worker()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 609, in spawn_worker
    worker.init_process()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/base.py", line 142, in init_process
    self.run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 126, in run
    self.run_for_one(timeout)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 70, in run_for_one
    self.accept(listener)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 32, in accept
    self.handle(listener, client, addr)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 135, in handle
    self.handle_request(listener, req, client, addr)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 178, in handle_request
    respiter = self.wsgi(environ, resp.start_response)
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 1478, in __call__
    return self.wsgi_app(environ, start_response)
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 1455, in wsgi_app
    response = self.full_dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 867, in full_dispatch_request
    rv = self.dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 852, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
  File "/home/onlyvedansh/cogagent2/finale.py", line 154, in initiate
    app.predictor=Predictor()
  File "/home/onlyvedansh/cogagent2/finale.py", line 94, in __init__
    logger.error("[Language processor version]:", self.language_processor_version)
Message: '[Language processor version]:'
Arguments: ('chat',)
ERROR:finale:Exception on /initiate [GET]
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 1455, in wsgi_app
    response = self.full_dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 870, in full_dispatch_request
    return self.finalize_request(rv)
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 889, in finalize_request
    response = self.make_response(rv)
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 1161, in make_response
    raise TypeError(
TypeError: The view function for 'initiate' did not return a valid response. The function either returned None or ended without a return statement.
ERROR:finale:click on images
ERROR:finale:Exception on /infer [GET]
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 1455, in wsgi_app
    response = self.full_dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 869, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 867, in full_dispatch_request
    rv = self.dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 852, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
  File "/home/onlyvedansh/cogagent2/finale.py", line 167, in infer
    answerdict=app.predictor.predict(string_data,imagepath)
  File "/home/onlyvedansh/cogagent2/finale.py", line 119, in predict
    self.response, self.history, self.cache_image = chat(
  File "/home/onlyvedansh/cogagent2/utils/utils/chat.py", line 53, in chat
    (torch_image, pil_img, cross_image) = process_image(image_path, img_processor, cross_img_processor, image)
  File "/home/onlyvedansh/cogagent2/utils/utils/chat.py", line 28, in process_image
    image = Image.open(image_path)
  File "/opt/conda/lib/python3.10/site-packages/PIL/Image.py", line 3243, in open
    fp = builtins.open(filename, "rb")
FileNotFoundError: [Errno 2] No such file or directory: '/home/onlyvedansh/cogagent2/utils/utils/utils/utils/a.jpg'
[2024-01-02 21:31:37 +0000] [4225] [INFO] Handling signal: int
[2024-01-02 21:31:37 +0000] [4226] [INFO] Worker exiting (pid: 4226)
[2024-01-02 21:31:39 +0000] [4225] [INFO] Shutting down: Master
[2024-01-02 21:34:10 +0000] [5128] [INFO] Starting gunicorn 21.2.0
[2024-01-02 21:34:10 +0000] [5128] [INFO] Listening at: http://0.0.0.0:8000 (5128)
[2024-01-02 21:34:10 +0000] [5128] [INFO] Using worker: sync
[2024-01-02 21:34:10 +0000] [5129] [INFO] Booting worker with pid: 5129
[2024-01-02 21:34:22,469] [INFO] building CogAgentModel model ...
[2024-01-02 21:34:22,471] [INFO] [RANK 0] > initializing model parallel with size 1
[2024-01-02 21:34:22,472] [INFO] [RANK 0] You didn't pass in LOCAL_WORLD_SIZE environment variable. We use the guessed LOCAL_WORLD_SIZE=1. If this is wrong, please pass the LOCAL_WORLD_SIZE manually.
[2024-01-02 21:34:22,472] [INFO] [RANK 0] You are using model-only mode.
For torch.distributed users or loading model parallel models, set environment variables RANK, WORLD_SIZE and LOCAL_RANK.
[2024-01-02 21:34:51,528] [INFO] [RANK 0]  > number of parameters on model parallel rank 0: 18291033280
INFO:sat:[RANK 0]  > number of parameters on model parallel rank 0: 18291033280
[2024-01-02 21:34:56,918] [INFO] [RANK 0] global rank 0 is loading checkpoint /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
INFO:sat:[RANK 0] global rank 0 is loading checkpoint /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
[2024-01-02 21:35:20,131] [INFO] [RANK 0] > successfully loaded /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
INFO:sat:[RANK 0] > successfully loaded /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
--- Logging error ---
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 1100, in emit
    msg = self.format(record)
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 943, in format
    return fmt.format(record)
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 678, in format
    record.message = record.getMessage()
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 368, in getMessage
    msg = msg % self.args
TypeError: not all arguments converted during string formatting
Call stack:
  File "/opt/conda/bin/gunicorn", line 8, in <module>
    sys.exit(run())
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py", line 67, in run
    WSGIApplication("%(prog)s [OPTIONS] [APP_MODULE]").run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/app/base.py", line 236, in run
    super().run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/app/base.py", line 72, in run
    Arbiter(self).run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 202, in run
    self.manage_workers()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 571, in manage_workers
    self.spawn_workers()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 642, in spawn_workers
    self.spawn_worker()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 609, in spawn_worker
    worker.init_process()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/base.py", line 142, in init_process
    self.run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 126, in run
    self.run_for_one(timeout)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 70, in run_for_one
    self.accept(listener)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 32, in accept
    self.handle(listener, client, addr)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 135, in handle
    self.handle_request(listener, req, client, addr)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 178, in handle_request
    respiter = self.wsgi(environ, resp.start_response)
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 1478, in __call__
    return self.wsgi_app(environ, start_response)
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 1455, in wsgi_app
    response = self.full_dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 867, in full_dispatch_request
    rv = self.dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 852, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
  File "/home/onlyvedansh/cogagent2/finale.py", line 154, in initiate
    app.predictor=Predictor()
  File "/home/onlyvedansh/cogagent2/finale.py", line 94, in __init__
    logger.error("[Language processor version]:", self.language_processor_version)
Message: '[Language processor version]:'
Arguments: ('chat',)
ERROR:finale:Exception on /initiate [GET]
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 1455, in wsgi_app
    response = self.full_dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 870, in full_dispatch_request
    return self.finalize_request(rv)
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 889, in finalize_request
    response = self.make_response(rv)
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 1161, in make_response
    raise TypeError(
TypeError: The view function for 'initiate' did not return a valid response. The function either returned None or ended without a return statement.
ERROR:finale:click on images
ERROR:finale:The 'Images' tab is highlighted, indicating that the user is currently viewing the Images search results.
ERROR:finale:Exception on /infer [GET]
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 1455, in wsgi_app
    response = self.full_dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 869, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 867, in full_dispatch_request
    rv = self.dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 852, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
  File "/home/onlyvedansh/cogagent2/finale.py", line 170, in infer
    return jsonify({'cmd': answerdict['cmd'],'imgtype':type(answerdict['img'])})
  File "/opt/conda/lib/python3.10/site-packages/flask/json/__init__.py", line 170, in jsonify
    return current_app.json.response(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/flask/json/provider.py", line 215, in response
    f"{self.dumps(obj, **dump_args)}\n", mimetype=self.mimetype
  File "/opt/conda/lib/python3.10/site-packages/flask/json/provider.py", line 180, in dumps
    return json.dumps(obj, **kwargs)
  File "/opt/conda/lib/python3.10/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
  File "/opt/conda/lib/python3.10/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/opt/conda/lib/python3.10/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/opt/conda/lib/python3.10/site-packages/flask/json/provider.py", line 120, in _default
    raise TypeError(f"Object of type {type(o).__name__} is not JSON serializable")
TypeError: Object of type type is not JSON serializable
[2024-01-02 21:37:01 +0000] [5128] [INFO] Handling signal: int
[2024-01-02 21:37:01 +0000] [5129] [INFO] Worker exiting (pid: 5129)
[2024-01-02 21:37:03 +0000] [5128] [INFO] Shutting down: Master
[2024-01-02 21:42:22 +0000] [6109] [INFO] Starting gunicorn 21.2.0
[2024-01-02 21:42:22 +0000] [6109] [INFO] Listening at: http://0.0.0.0:8000 (6109)
[2024-01-02 21:42:22 +0000] [6109] [INFO] Using worker: sync
[2024-01-02 21:42:22 +0000] [6110] [INFO] Booting worker with pid: 6110
[2024-01-02 21:42:48,350] [INFO] building CogAgentModel model ...
[2024-01-02 21:42:48,352] [INFO] [RANK 0] > initializing model parallel with size 1
[2024-01-02 21:42:48,353] [INFO] [RANK 0] You didn't pass in LOCAL_WORLD_SIZE environment variable. We use the guessed LOCAL_WORLD_SIZE=1. If this is wrong, please pass the LOCAL_WORLD_SIZE manually.
[2024-01-02 21:42:48,353] [INFO] [RANK 0] You are using model-only mode.
For torch.distributed users or loading model parallel models, set environment variables RANK, WORLD_SIZE and LOCAL_RANK.
[2024-01-02 21:43:17,369] [INFO] [RANK 0]  > number of parameters on model parallel rank 0: 18291033280
INFO:sat:[RANK 0]  > number of parameters on model parallel rank 0: 18291033280
[2024-01-02 21:43:22,751] [INFO] [RANK 0] global rank 0 is loading checkpoint /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
INFO:sat:[RANK 0] global rank 0 is loading checkpoint /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
[2024-01-02 21:43:44,529] [INFO] [RANK 0] > successfully loaded /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
INFO:sat:[RANK 0] > successfully loaded /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
--- Logging error ---
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 1100, in emit
    msg = self.format(record)
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 943, in format
    return fmt.format(record)
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 678, in format
    record.message = record.getMessage()
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 368, in getMessage
    msg = msg % self.args
TypeError: not all arguments converted during string formatting
Call stack:
  File "/opt/conda/bin/gunicorn", line 8, in <module>
    sys.exit(run())
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py", line 67, in run
    WSGIApplication("%(prog)s [OPTIONS] [APP_MODULE]").run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/app/base.py", line 236, in run
    super().run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/app/base.py", line 72, in run
    Arbiter(self).run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 202, in run
    self.manage_workers()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 571, in manage_workers
    self.spawn_workers()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 642, in spawn_workers
    self.spawn_worker()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 609, in spawn_worker
    worker.init_process()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/base.py", line 142, in init_process
    self.run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 126, in run
    self.run_for_one(timeout)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 70, in run_for_one
    self.accept(listener)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 32, in accept
    self.handle(listener, client, addr)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 135, in handle
    self.handle_request(listener, req, client, addr)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 178, in handle_request
    respiter = self.wsgi(environ, resp.start_response)
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 1478, in __call__
    return self.wsgi_app(environ, start_response)
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 1455, in wsgi_app
    response = self.full_dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 867, in full_dispatch_request
    rv = self.dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 852, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
  File "/home/onlyvedansh/cogagent2/finale.py", line 154, in initiate
    app.predictor=Predictor()
  File "/home/onlyvedansh/cogagent2/finale.py", line 94, in __init__
    logger.error("[Language processor version]:", self.language_processor_version)
Message: '[Language processor version]:'
Arguments: ('chat',)
ERROR:finale:what steps do i need to take to click on images
ERROR:finale:Plan: 1. Locate the 'Images' tab. 2. Click on the 'Images' tab to view images.
Next Action: Move the cursor to the top of the screen and click on the 'Images' tab, which is the second tab from the left.
ERROR:finale:what steps do i need to take to click on images
ERROR:finale:Plan: 1. Locate the 'Images' tab. 2. Click on the 'Images' tab to view images.
Next Action: Move the cursor to the top of the screen and click on the 'Images' tab, which is the second tab from the left.
[2024-01-02 21:48:54 +0000] [6109] [INFO] Handling signal: int
[2024-01-02 21:48:54 +0000] [6110] [INFO] Worker exiting (pid: 6110)
[2024-01-02 21:48:55 +0000] [6109] [INFO] Shutting down: Master
[2024-01-02 22:20:42 +0000] [4791] [INFO] Starting gunicorn 21.2.0
[2024-01-02 22:20:42 +0000] [4791] [INFO] Listening at: http://0.0.0.0:8000 (4791)
[2024-01-02 22:20:42 +0000] [4791] [INFO] Using worker: sync
[2024-01-02 22:20:42 +0000] [4808] [INFO] Booting worker with pid: 4808
[2024-01-02 22:21:48,498] [INFO] building CogAgentModel model ...
[2024-01-02 22:21:48,504] [INFO] [RANK 0] > initializing model parallel with size 1
[2024-01-02 22:21:48,505] [INFO] [RANK 0] You didn't pass in LOCAL_WORLD_SIZE environment variable. We use the guessed LOCAL_WORLD_SIZE=1. If this is wrong, please pass the LOCAL_WORLD_SIZE manually.
[2024-01-02 22:21:48,506] [INFO] [RANK 0] You are using model-only mode.
For torch.distributed users or loading model parallel models, set environment variables RANK, WORLD_SIZE and LOCAL_RANK.
[2024-01-02 22:22:17,767] [INFO] [RANK 0]  > number of parameters on model parallel rank 0: 18291033280
INFO:sat:[RANK 0]  > number of parameters on model parallel rank 0: 18291033280
[2024-01-02 22:22:23,164] [INFO] [RANK 0] global rank 0 is loading checkpoint /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
INFO:sat:[RANK 0] global rank 0 is loading checkpoint /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
[2024-01-02 22:24:15,510] [INFO] [RANK 0] > successfully loaded /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
INFO:sat:[RANK 0] > successfully loaded /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
--- Logging error ---
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 1100, in emit
    msg = self.format(record)
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 943, in format
    return fmt.format(record)
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 678, in format
    record.message = record.getMessage()
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 368, in getMessage
    msg = msg % self.args
TypeError: not all arguments converted during string formatting
Call stack:
  File "/opt/conda/bin/gunicorn", line 8, in <module>
    sys.exit(run())
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py", line 67, in run
    WSGIApplication("%(prog)s [OPTIONS] [APP_MODULE]").run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/app/base.py", line 236, in run
    super().run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/app/base.py", line 72, in run
    Arbiter(self).run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 202, in run
    self.manage_workers()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 571, in manage_workers
    self.spawn_workers()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 642, in spawn_workers
    self.spawn_worker()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 609, in spawn_worker
    worker.init_process()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/base.py", line 142, in init_process
    self.run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 126, in run
    self.run_for_one(timeout)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 70, in run_for_one
    self.accept(listener)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 32, in accept
    self.handle(listener, client, addr)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 135, in handle
    self.handle_request(listener, req, client, addr)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 178, in handle_request
    respiter = self.wsgi(environ, resp.start_response)
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 1478, in __call__
    return self.wsgi_app(environ, start_response)
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 1455, in wsgi_app
    response = self.full_dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 867, in full_dispatch_request
    rv = self.dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 852, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
  File "/home/onlyvedansh/cogagent2/finale.py", line 154, in initiate
    app.predictor=Predictor()
  File "/home/onlyvedansh/cogagent2/finale.py", line 94, in __init__
    logger.error("[Language processor version]:", self.language_processor_version)
Message: '[Language processor version]:'
Arguments: ('chat',)
ERROR:finale:click on gmail (with grounding)
ERROR:finale:Plan: 1. Click on the 'Gmail' link located at the top right corner of the screen. 2. Wait for the Gmail application to open. 3. Once the Gmail application is open, check for any new emails or notifications. 4. Respond to any emails if necessary or begin composing a new email.
Next Action: Move the cursor to the top right corner of the screen where the 'Gmail' link is located and perform a click operation.
Grounded Operation:[link] Gmail -> CLICK at the box [[771,026,805,062]]
[2024-01-02 22:43:50 +0000] [4791] [INFO] Handling signal: int
[2024-01-02 22:43:50 +0000] [4808] [INFO] Worker exiting (pid: 4808)
[2024-01-02 22:43:52 +0000] [4791] [INFO] Shutting down: Master
[2024-01-03 21:44:15 +0000] [5852] [INFO] Starting gunicorn 21.2.0
[2024-01-03 21:44:15 +0000] [5852] [INFO] Listening at: http://0.0.0.0:8000 (5852)
[2024-01-03 21:44:15 +0000] [5852] [INFO] Using worker: sync
[2024-01-03 21:44:15 +0000] [5853] [INFO] Booting worker with pid: 5853
[2024-01-03 21:46:31,237] [INFO] building CogAgentModel model ...
[2024-01-03 21:46:31,243] [INFO] [RANK 0] > initializing model parallel with size 1
[2024-01-03 21:46:31,244] [INFO] [RANK 0] You didn't pass in LOCAL_WORLD_SIZE environment variable. We use the guessed LOCAL_WORLD_SIZE=1. If this is wrong, please pass the LOCAL_WORLD_SIZE manually.
[2024-01-03 21:46:31,245] [INFO] [RANK 0] You are using model-only mode.
For torch.distributed users or loading model parallel models, set environment variables RANK, WORLD_SIZE and LOCAL_RANK.
[2024-01-03 21:47:00,535] [INFO] [RANK 0]  > number of parameters on model parallel rank 0: 18291033280
INFO:sat:[RANK 0]  > number of parameters on model parallel rank 0: 18291033280
[2024-01-03 21:47:05,956] [INFO] [RANK 0] global rank 0 is loading checkpoint /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
INFO:sat:[RANK 0] global rank 0 is loading checkpoint /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
[2024-01-03 21:48:55,259] [INFO] [RANK 0] > successfully loaded /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
INFO:sat:[RANK 0] > successfully loaded /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
--- Logging error ---
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 1100, in emit
    msg = self.format(record)
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 943, in format
    return fmt.format(record)
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 678, in format
    record.message = record.getMessage()
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 368, in getMessage
    msg = msg % self.args
TypeError: not all arguments converted during string formatting
Call stack:
  File "/opt/conda/bin/gunicorn", line 8, in <module>
    sys.exit(run())
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py", line 67, in run
    WSGIApplication("%(prog)s [OPTIONS] [APP_MODULE]").run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/app/base.py", line 236, in run
    super().run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/app/base.py", line 72, in run
    Arbiter(self).run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 202, in run
    self.manage_workers()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 571, in manage_workers
    self.spawn_workers()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 642, in spawn_workers
    self.spawn_worker()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 609, in spawn_worker
    worker.init_process()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/base.py", line 142, in init_process
    self.run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 126, in run
    self.run_for_one(timeout)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 70, in run_for_one
    self.accept(listener)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 32, in accept
    self.handle(listener, client, addr)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 135, in handle
    self.handle_request(listener, req, client, addr)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 178, in handle_request
    respiter = self.wsgi(environ, resp.start_response)
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 1478, in __call__
    return self.wsgi_app(environ, start_response)
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 1455, in wsgi_app
    response = self.full_dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 867, in full_dispatch_request
    rv = self.dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 852, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
  File "/home/onlyvedansh/cogagent2/finale.py", line 154, in initiate
    app.predictor=Predictor()
  File "/home/onlyvedansh/cogagent2/finale.py", line 94, in __init__
    logger.error("[Language processor version]:", self.language_processor_version)
Message: '[Language processor version]:'
Arguments: ('chat',)
ERROR:finale:What steps do I need to take to "type codecademy in the search box"?(with grounding)
ERROR:finale:Plan: 1. Move the cursor to the search box located approximately in the center of the screen. 2. Click on the search box to activate it for typing. 3. Type 'codecademy' into the search box. 4. Press the 'Enter' key or click on the search icon to initiate the search.
Next Action: Move the cursor to the center of the screen where the search box is located and click to activate it for typing.
Grounded Operation:[combobox]  Search -> CLICK at the box [[265,308,676,376]]
ERROR:finale:What steps do I need to take to "type codecademy in a search box"?(with grounding)
ERROR:finale:Plan: 1. Move the cursor to the search box located approximately in the center of the screen. 2. Click on the search box to activate it for typing. 3. Type 'codecademy' into the search box. 4. Press the 'Enter' key or click on the search icon to initiate the search.
Next Action: Move the cursor to the center of the screen where the search box is located and click to activate it for typing.
Grounded Operation:[combobox]  Search -> CLICK at the box [[265,308,676,376]]
[2024-01-03 22:14:50 +0000] [5852] [INFO] Handling signal: int
[2024-01-03 22:14:50 +0000] [5853] [INFO] Worker exiting (pid: 5853)
[2024-01-03 22:14:51 +0000] [5852] [INFO] Shutting down: Master
[2024-01-03 23:39:26 +0000] [4040] [INFO] Starting gunicorn 21.2.0
[2024-01-03 23:39:26 +0000] [4040] [INFO] Listening at: http://0.0.0.0:8000 (4040)
[2024-01-03 23:39:26 +0000] [4040] [INFO] Using worker: sync
[2024-01-03 23:39:26 +0000] [4041] [INFO] Booting worker with pid: 4041
[2024-01-03 23:39:45,866] [INFO] building CogAgentModel model ...
[2024-01-03 23:39:45,871] [INFO] [RANK 0] > initializing model parallel with size 1
[2024-01-03 23:39:45,872] [INFO] [RANK 0] You didn't pass in LOCAL_WORLD_SIZE environment variable. We use the guessed LOCAL_WORLD_SIZE=1. If this is wrong, please pass the LOCAL_WORLD_SIZE manually.
[2024-01-03 23:39:45,874] [INFO] [RANK 0] You are using model-only mode.
For torch.distributed users or loading model parallel models, set environment variables RANK, WORLD_SIZE and LOCAL_RANK.
[2024-01-03 23:40:15,087] [INFO] [RANK 0]  > number of parameters on model parallel rank 0: 18291033280
INFO:sat:[RANK 0]  > number of parameters on model parallel rank 0: 18291033280
[2024-01-03 23:40:20,464] [INFO] [RANK 0] global rank 0 is loading checkpoint /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
INFO:sat:[RANK 0] global rank 0 is loading checkpoint /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
[2024-01-03 23:42:13,003] [INFO] [RANK 0] > successfully loaded /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
INFO:sat:[RANK 0] > successfully loaded /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
--- Logging error ---
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 1100, in emit
    msg = self.format(record)
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 943, in format
    return fmt.format(record)
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 678, in format
    record.message = record.getMessage()
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 368, in getMessage
    msg = msg % self.args
TypeError: not all arguments converted during string formatting
Call stack:
  File "/opt/conda/bin/gunicorn", line 8, in <module>
    sys.exit(run())
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py", line 67, in run
    WSGIApplication("%(prog)s [OPTIONS] [APP_MODULE]").run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/app/base.py", line 236, in run
    super().run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/app/base.py", line 72, in run
    Arbiter(self).run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 202, in run
    self.manage_workers()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 571, in manage_workers
    self.spawn_workers()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 642, in spawn_workers
    self.spawn_worker()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 609, in spawn_worker
    worker.init_process()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/base.py", line 142, in init_process
    self.run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 126, in run
    self.run_for_one(timeout)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 70, in run_for_one
    self.accept(listener)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 32, in accept
    self.handle(listener, client, addr)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 135, in handle
    self.handle_request(listener, req, client, addr)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 178, in handle_request
    respiter = self.wsgi(environ, resp.start_response)
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 1478, in __call__
    return self.wsgi_app(environ, start_response)
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 1455, in wsgi_app
    response = self.full_dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 867, in full_dispatch_request
    rv = self.dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 852, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
  File "/home/onlyvedansh/cogagent2/finale.py", line 154, in initiate
    app.predictor=Predictor()
  File "/home/onlyvedansh/cogagent2/finale.py", line 94, in __init__
    logger.error("[Language processor version]:", self.language_processor_version)
Message: '[Language processor version]:'
Arguments: ('chat',)
ERROR:finale:What steps do I need to take to "type codecademy in the search box"?(with grounding)
ERROR:finale:Plan: 1. Move the cursor to the search box located approximately in the center of the screen. 2. Click on the search box to activate it for typing. 3. Type 'codecademy' into the search box. 4. Press the enter key or click the search icon to initiate the search.
Next Action: Move the cursor to the center of the screen where the search box is located and click to activate it for typing.
Grounded Operation:[combobox]  Search -> CLICK at the box [[273,341,728,408]]
ERROR:finale:What steps do I need to take to "type codecademy in the search box"?(with grounding)
ERROR:finale:Plan: 1. Move the cursor to the search box located approximately in the center of the screen. 2. Click on the search box to activate it for typing. 3. Type 'codecademy' into the search box. 4. Press the enter key or click the search icon to initiate the search.
Next Action: Move the cursor to the center of the screen where the search box is located and click to activate it for typing.
Grounded Operation:[combobox]  Search -> CLICK at the box [[273,341,728,408]]
ERROR:finale:Describe the relevant contents on the web page
ERROR:finale:The screenshot shows a Google search page with a search bar at the top. The user has typed 'codecademy' into the search bar, and below it, there are suggested search terms such as 'happy new year wishes greetings quotes', 'delhi weather forecast', 'guardians vs voyagers scorecard', and others. There is a Google logo at the top, and on the right side, there is a 'Sign in to Google' button. The browser interface includes tabs for 'All', 'Images', 'Shopping', 'News', 'More', and a button to 'Sign in'. There are also options for 'I'm Feeling Lucky' and 'Report inappropriate predictions'.
ERROR:finale:What steps do I need to take to "click on google search"?(with grounding)
ERROR:finale:Plan: 1. Identify the Google Search bar or the search icon to initiate a search. 2. Click on the Google Search bar if it's not active. 3. Enter the search terms into the Google Search bar. 4. Execute the search by clicking the 'Search' button on the keyboard or the search icon next to the search bar.
Next Action: Move the cursor to the center of the screen where the list of search suggestions is displayed, specifically at the coordinates corresponding to the 'codecademy' option in the dropdown menu, and perform a click operation.
Grounded Operation:[span] codecademy -> CLICK at the box [[309,425,382,457]]
ERROR:finale:Describe the relevant contents on the web page
ERROR:finale:A detailed description of the webpage's contents is not available due to a processing error.
[2024-01-03 23:52:06 +0000] [4040] [INFO] Handling signal: int
[2024-01-03 23:52:06 +0000] [4041] [INFO] Worker exiting (pid: 4041)
[2024-01-03 23:52:07 +0000] [4040] [INFO] Shutting down: Master
[2024-01-04 12:35:27 +0000] [5946] [INFO] Starting gunicorn 21.2.0
[2024-01-04 12:35:27 +0000] [5946] [INFO] Listening at: http://0.0.0.0:8000 (5946)
[2024-01-04 12:35:27 +0000] [5946] [INFO] Using worker: sync
[2024-01-04 12:35:27 +0000] [5947] [INFO] Booting worker with pid: 5947
[2024-01-04 12:35:42,856] [INFO] building CogAgentModel model ...
[2024-01-04 12:35:42,862] [INFO] [RANK 0] > initializing model parallel with size 1
[2024-01-04 12:35:42,863] [INFO] [RANK 0] You didn't pass in LOCAL_WORLD_SIZE environment variable. We use the guessed LOCAL_WORLD_SIZE=1. If this is wrong, please pass the LOCAL_WORLD_SIZE manually.
[2024-01-04 12:35:42,864] [INFO] [RANK 0] You are using model-only mode.
For torch.distributed users or loading model parallel models, set environment variables RANK, WORLD_SIZE and LOCAL_RANK.
[2024-01-04 12:36:12,116] [INFO] [RANK 0]  > number of parameters on model parallel rank 0: 18291033280
INFO:sat:[RANK 0]  > number of parameters on model parallel rank 0: 18291033280
[2024-01-04 12:36:17,557] [INFO] [RANK 0] global rank 0 is loading checkpoint /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
INFO:sat:[RANK 0] global rank 0 is loading checkpoint /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
[2024-01-04 12:38:14,404] [INFO] [RANK 0] > successfully loaded /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
INFO:sat:[RANK 0] > successfully loaded /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
--- Logging error ---
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 1100, in emit
    msg = self.format(record)
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 943, in format
    return fmt.format(record)
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 678, in format
    record.message = record.getMessage()
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 368, in getMessage
    msg = msg % self.args
TypeError: not all arguments converted during string formatting
Call stack:
  File "/opt/conda/bin/gunicorn", line 8, in <module>
    sys.exit(run())
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py", line 67, in run
    WSGIApplication("%(prog)s [OPTIONS] [APP_MODULE]").run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/app/base.py", line 236, in run
    super().run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/app/base.py", line 72, in run
    Arbiter(self).run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 202, in run
    self.manage_workers()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 571, in manage_workers
    self.spawn_workers()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 642, in spawn_workers
    self.spawn_worker()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 609, in spawn_worker
    worker.init_process()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/base.py", line 142, in init_process
    self.run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 126, in run
    self.run_for_one(timeout)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 70, in run_for_one
    self.accept(listener)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 32, in accept
    self.handle(listener, client, addr)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 135, in handle
    self.handle_request(listener, req, client, addr)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 178, in handle_request
    respiter = self.wsgi(environ, resp.start_response)
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 1478, in __call__
    return self.wsgi_app(environ, start_response)
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 1455, in wsgi_app
    response = self.full_dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 867, in full_dispatch_request
    rv = self.dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 852, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
  File "/home/onlyvedansh/cogagent2/finale.py", line 154, in initiate
    app.predictor=Predictor()
  File "/home/onlyvedansh/cogagent2/finale.py", line 94, in __init__
    logger.error("[Language processor version]:", self.language_processor_version)
Message: '[Language processor version]:'
Arguments: ('chat',)
[2024-01-04 12:42:44 +0000] [5946] [INFO] Handling signal: int
[2024-01-04 12:42:44 +0000] [5947] [INFO] Worker exiting (pid: 5947)
[2024-01-04 12:42:46 +0000] [5946] [INFO] Shutting down: Master
[2024-01-04 17:38:49 +0000] [4144] [INFO] Starting gunicorn 21.2.0
[2024-01-04 17:38:49 +0000] [4144] [INFO] Listening at: http://0.0.0.0:8000 (4144)
[2024-01-04 17:38:49 +0000] [4144] [INFO] Using worker: sync
[2024-01-04 17:38:49 +0000] [4145] [INFO] Booting worker with pid: 4145
[2024-01-04 17:39:04,948] [INFO] building CogAgentModel model ...
[2024-01-04 17:39:04,954] [INFO] [RANK 0] > initializing model parallel with size 1
[2024-01-04 17:39:04,954] [INFO] [RANK 0] You didn't pass in LOCAL_WORLD_SIZE environment variable. We use the guessed LOCAL_WORLD_SIZE=1. If this is wrong, please pass the LOCAL_WORLD_SIZE manually.
[2024-01-04 17:39:04,955] [INFO] [RANK 0] You are using model-only mode.
For torch.distributed users or loading model parallel models, set environment variables RANK, WORLD_SIZE and LOCAL_RANK.
[2024-01-04 17:39:34,188] [INFO] [RANK 0]  > number of parameters on model parallel rank 0: 18291033280
INFO:sat:[RANK 0]  > number of parameters on model parallel rank 0: 18291033280
[2024-01-04 17:39:39,572] [INFO] [RANK 0] global rank 0 is loading checkpoint /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
INFO:sat:[RANK 0] global rank 0 is loading checkpoint /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
[2024-01-04 17:41:30,716] [INFO] [RANK 0] > successfully loaded /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
INFO:sat:[RANK 0] > successfully loaded /home/onlyvedansh/.sat_models/cogagent-chat/1/mp_rank_00_model_states.pt
--- Logging error ---
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 1100, in emit
    msg = self.format(record)
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 943, in format
    return fmt.format(record)
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 678, in format
    record.message = record.getMessage()
  File "/opt/conda/lib/python3.10/logging/__init__.py", line 368, in getMessage
    msg = msg % self.args
TypeError: not all arguments converted during string formatting
Call stack:
  File "/opt/conda/bin/gunicorn", line 8, in <module>
    sys.exit(run())
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py", line 67, in run
    WSGIApplication("%(prog)s [OPTIONS] [APP_MODULE]").run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/app/base.py", line 236, in run
    super().run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/app/base.py", line 72, in run
    Arbiter(self).run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 202, in run
    self.manage_workers()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 571, in manage_workers
    self.spawn_workers()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 642, in spawn_workers
    self.spawn_worker()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/arbiter.py", line 609, in spawn_worker
    worker.init_process()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/base.py", line 142, in init_process
    self.run()
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 126, in run
    self.run_for_one(timeout)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 70, in run_for_one
    self.accept(listener)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 32, in accept
    self.handle(listener, client, addr)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 135, in handle
    self.handle_request(listener, req, client, addr)
  File "/opt/conda/lib/python3.10/site-packages/gunicorn/workers/sync.py", line 178, in handle_request
    respiter = self.wsgi(environ, resp.start_response)
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 1478, in __call__
    return self.wsgi_app(environ, start_response)
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 1455, in wsgi_app
    response = self.full_dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 867, in full_dispatch_request
    rv = self.dispatch_request()
  File "/opt/conda/lib/python3.10/site-packages/flask/app.py", line 852, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
  File "/home/onlyvedansh/cogagent2/finale.py", line 154, in initiate
    app.predictor=Predictor()
  File "/home/onlyvedansh/cogagent2/finale.py", line 94, in __init__
    logger.error("[Language processor version]:", self.language_processor_version)
Message: '[Language processor version]:'
Arguments: ('chat',)
[2024-01-04 17:56:02 +0000] [4144] [INFO] Handling signal: int
[2024-01-04 17:56:02 +0000] [4145] [INFO] Worker exiting (pid: 4145)
[2024-01-04 17:56:04 +0000] [4144] [INFO] Shutting down: Master
